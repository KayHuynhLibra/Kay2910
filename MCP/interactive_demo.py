#!/usr/bin/env python3
"""
Interactive Demo - AI 2025 v·ªõi MCP
Demo t∆∞∆°ng t√°c ƒë·ªÉ th·ª≠ nghi·ªám c√°c t√≠nh nƒÉng
"""

import json
import numpy as np
import torch
from datetime import datetime

class InteractiveMCPServer:
    """MCP Server t∆∞∆°ng t√°c"""
    
    def __init__(self):
        self.resources = {
            "database": {
                "type": "sqlite",
                "tables": ["users", "products", "orders"],
                "data": self._load_sample_data()
            },
            "filesystem": {
                "type": "local",
                "root": "./data",
                "files": ["sample_data.json", "config.json"]
            },
            "api": {
                "type": "rest",
                "endpoints": ["/users", "/products", "/analytics"],
                "status": "online"
            }
        }
        
        self.tools = {
            "analyze_data": {
                "description": "Ph√¢n t√≠ch d·ªØ li·ªáu",
                "parameters": ["dataset", "operation"]
            },
            "process_file": {
                "description": "X·ª≠ l√Ω file",
                "parameters": ["file_path", "operation"]
            },
            "generate_text": {
                "description": "T·∫°o vƒÉn b·∫£n",
                "parameters": ["prompt", "max_length"]
            },
            "train_model": {
                "description": "Hu·∫•n luy·ªán model",
                "parameters": ["model_type", "epochs"]
            }
        }
        
        self.memory = []
    
    def _load_sample_data(self):
        """Load d·ªØ li·ªáu m·∫´u"""
        try:
            with open("data/sample_data.json", "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return {"error": "Kh√¥ng th·ªÉ load d·ªØ li·ªáu"}
    
    def list_resources(self):
        """Li·ªát k√™ t√†i nguy√™n"""
        return list(self.resources.keys())
    
    def read_resource(self, resource_name):
        """ƒê·ªçc t√†i nguy√™n"""
        if resource_name in self.resources:
            return self.resources[resource_name]
        return {"error": f"T√†i nguy√™n {resource_name} kh√¥ng t·ªìn t·∫°i"}
    
    def list_tools(self):
        """Li·ªát k√™ c√¥ng c·ª•"""
        return list(self.tools.keys())
    
    def call_tool(self, tool_name, parameters):
        """G·ªçi c√¥ng c·ª•"""
        if tool_name not in self.tools:
            return {"error": f"C√¥ng c·ª• {tool_name} kh√¥ng t·ªìn t·∫°i"}
        
        # Log tool call
        self.memory.append({
            "timestamp": datetime.now().isoformat(),
            "tool": tool_name,
            "parameters": parameters
        })
        
        # Execute tool
        if tool_name == "analyze_data":
            return self._analyze_data(parameters)
        elif tool_name == "process_file":
            return self._process_file(parameters)
        elif tool_name == "generate_text":
            return self._generate_text(parameters)
        elif tool_name == "train_model":
            return self._train_model(parameters)
    
    def _analyze_data(self, params):
        """Ph√¢n t√≠ch d·ªØ li·ªáu"""
        dataset = params.get("dataset", "users")
        operation = params.get("operation", "summary")
        
        if dataset in self.resources["database"]["data"]:
            data = self.resources["database"]["data"][dataset]
            
            if operation == "summary":
                return {
                    "dataset": dataset,
                    "count": len(data),
                    "operation": operation,
                    "summary": f"Dataset {dataset} c√≥ {len(data)} records"
                }
            elif operation == "statistics":
                if dataset == "products":
                    prices = [item["price"] for item in data]
                    return {
                        "dataset": dataset,
                        "count": len(data),
                        "avg_price": np.mean(prices),
                        "min_price": np.min(prices),
                        "max_price": np.max(prices)
                    }
        
        return {"error": f"Kh√¥ng th·ªÉ ph√¢n t√≠ch dataset {dataset}"}
    
    def _process_file(self, params):
        """X·ª≠ l√Ω file"""
        file_path = params.get("file_path", "")
        operation = params.get("operation", "read")
        
        if operation == "read":
            if file_path == "sample_data.json":
                return {
                    "file": file_path,
                    "operation": operation,
                    "content": "D·ªØ li·ªáu m·∫´u ƒë√£ ƒë∆∞·ª£c ƒë·ªçc th√†nh c√¥ng"
                }
        
        return {
            "file": file_path,
            "operation": operation,
            "status": "completed"
        }
    
    def _generate_text(self, params):
        """T·∫°o vƒÉn b·∫£n"""
        prompt = params.get("prompt", "")
        max_length = params.get("max_length", 100)
        
        # M√¥ ph·ªèng text generation
        responses = [
            f"D·ª±a tr√™n prompt '{prompt}', ƒë√¢y l√† m·ªôt ph·∫£n h·ªìi m·∫´u v·ªÅ AI 2025.",
            f"AI 2025 v·ªõi MCP s·∫Ω c√°ch m·∫°ng h√≥a c√°ch ch√∫ng ta t∆∞∆°ng t√°c v·ªõi m√°y t√≠nh.",
            f"Model Context Protocol (MCP) l√† t∆∞∆°ng lai c·ªßa AI integration.",
            f"Multimodal AI s·∫Ω cho ph√©p x·ª≠ l√Ω text, image, audio v√† video c√πng l√∫c."
        ]
        
        import random
        response = random.choice(responses)
        
        return {
            "prompt": prompt,
            "response": response[:max_length],
            "length": len(response[:max_length])
        }
    
    def _train_model(self, params):
        """Hu·∫•n luy·ªán model"""
        model_type = params.get("model_type", "transformer")
        epochs = params.get("epochs", 3)
        
        # M√¥ ph·ªèng training
        training_log = []
        for epoch in range(epochs):
            loss = 1.0 / (epoch + 1) + np.random.normal(0, 0.1)
            accuracy = 0.8 + epoch * 0.05 + np.random.normal(0, 0.02)
            
            training_log.append({
                "epoch": epoch + 1,
                "loss": round(loss, 4),
                "accuracy": round(accuracy, 4)
            })
        
        return {
            "model_type": model_type,
            "epochs": epochs,
            "training_log": training_log,
            "final_accuracy": training_log[-1]["accuracy"]
        }
    
    def get_memory(self):
        """L·∫•y l·ªãch s·ª≠ ho·∫°t ƒë·ªông"""
        return self.memory

def print_menu():
    """In menu ch√≠nh"""
    print("\n" + "="*60)
    print("üöÄ AI 2025 v·ªõi MCP - Interactive Demo")
    print("="*60)
    print("1. Li·ªát k√™ t√†i nguy√™n")
    print("2. ƒê·ªçc t√†i nguy√™n")
    print("3. Li·ªát k√™ c√¥ng c·ª•")
    print("4. Ph√¢n t√≠ch d·ªØ li·ªáu")
    print("5. X·ª≠ l√Ω file")
    print("6. T·∫°o vƒÉn b·∫£n")
    print("7. Hu·∫•n luy·ªán model")
    print("8. Xem l·ªãch s·ª≠")
    print("9. Tho√°t")
    print("="*60)

def main():
    """H√†m ch√≠nh"""
    print("üéâ Ch√†o m·ª´ng ƒë·∫øn v·ªõi AI 2025 v·ªõi MCP!")
    print("üí° ƒê√¢y l√† demo t∆∞∆°ng t√°c ƒë·ªÉ th·ª≠ nghi·ªám c√°c t√≠nh nƒÉng")
    
    # Kh·ªüi t·∫°o MCP server
    mcp_server = InteractiveMCPServer()
    
    while True:
        print_menu()
        
        try:
            choice = input("Ch·ªçn t√πy ch·ªçn (1-9): ").strip()
            
            if choice == "1":
                # Li·ªát k√™ t√†i nguy√™n
                resources = mcp_server.list_resources()
                print(f"\nüìã T√†i nguy√™n c√≥ s·∫µn: {resources}")
                
            elif choice == "2":
                # ƒê·ªçc t√†i nguy√™n
                resource_name = input("Nh·∫≠p t√™n t√†i nguy√™n (database/filesystem/api): ").strip()
                result = mcp_server.read_resource(resource_name)
                print(f"\nüìñ K·∫øt qu·∫£: {json.dumps(result, indent=2, ensure_ascii=False)}")
                
            elif choice == "3":
                # Li·ªát k√™ c√¥ng c·ª•
                tools = mcp_server.list_tools()
                print(f"\nüõ†Ô∏è C√¥ng c·ª• c√≥ s·∫µn:")
                for tool in tools:
                    print(f"   - {tool}: {mcp_server.tools[tool]['description']}")
                
            elif choice == "4":
                # Ph√¢n t√≠ch d·ªØ li·ªáu
                dataset = input("Nh·∫≠p dataset (users/products/orders): ").strip()
                operation = input("Nh·∫≠p operation (summary/statistics): ").strip()
                
                result = mcp_server.call_tool("analyze_data", {
                    "dataset": dataset,
                    "operation": operation
                })
                print(f"\nüìä K·∫øt qu·∫£ ph√¢n t√≠ch: {json.dumps(result, indent=2, ensure_ascii=False)}")
                
            elif choice == "5":
                # X·ª≠ l√Ω file
                file_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n file: ").strip()
                operation = input("Nh·∫≠p operation (read/write): ").strip()
                
                result = mcp_server.call_tool("process_file", {
                    "file_path": file_path,
                    "operation": operation
                })
                print(f"\nüìÅ K·∫øt qu·∫£ x·ª≠ l√Ω file: {json.dumps(result, indent=2, ensure_ascii=False)}")
                
            elif choice == "6":
                # T·∫°o vƒÉn b·∫£n
                prompt = input("Nh·∫≠p prompt: ").strip()
                max_length = int(input("Nh·∫≠p ƒë·ªô d√†i t·ªëi ƒëa (s·ªë): ").strip())
                
                result = mcp_server.call_tool("generate_text", {
                    "prompt": prompt,
                    "max_length": max_length
                })
                print(f"\nüìù K·∫øt qu·∫£ t·∫°o vƒÉn b·∫£n: {json.dumps(result, indent=2, ensure_ascii=False)}")
                
            elif choice == "7":
                # Hu·∫•n luy·ªán model
                model_type = input("Nh·∫≠p lo·∫°i model (transformer/cnn/rnn): ").strip()
                epochs = int(input("Nh·∫≠p s·ªë epochs (s·ªë): ").strip())
                
                result = mcp_server.call_tool("train_model", {
                    "model_type": model_type,
                    "epochs": epochs
                })
                print(f"\nüß† K·∫øt qu·∫£ hu·∫•n luy·ªán: {json.dumps(result, indent=2, ensure_ascii=False)}")
                
            elif choice == "8":
                # Xem l·ªãch s·ª≠
                memory = mcp_server.get_memory()
                print(f"\nüìö L·ªãch s·ª≠ ho·∫°t ƒë·ªông:")
                for i, record in enumerate(memory[-5:], 1):  # Hi·ªÉn th·ªã 5 record g·∫ßn nh·∫•t
                    print(f"   {i}. {record['timestamp']} - {record['tool']}: {record['parameters']}")
                
            elif choice == "9":
                # Tho√°t
                print("\nüëã C·∫£m ∆°n b·∫°n ƒë√£ th·ª≠ nghi·ªám AI 2025 v·ªõi MCP!")
                print("üöÄ H·∫πn g·∫∑p l·∫°i trong h√†nh tr√¨nh AI!")
                break
                
            else:
                print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. Vui l√≤ng ch·ªçn t·ª´ 1-9.")
                
        except KeyboardInterrupt:
            print("\n\nüëã T·∫°m bi·ªát!")
            break
        except Exception as e:
            print(f"‚ùå L·ªói: {e}")
            print("üí° Vui l√≤ng th·ª≠ l·∫°i")

if __name__ == "__main__":
    main() 