# ğŸš€ Project - 02 Intermediate

## ğŸ“‹ MÃ´ Táº£ Dá»± Ãn / Project Description

**Tiáº¿ng Viá»‡t:** XÃ¢y dá»±ng má»™t há»‡ thá»‘ng hoÃ n chá»‰nh sá»­ dá»¥ng 02 Intermediate Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n thá»±c táº¿.

**English:** Build a complete system using 02 Intermediate to solve a real-world problem.

## ğŸ¯ Má»¥c TiÃªu / Objectives

1. **Hiá»ƒu sÃ¢u vá» 02 Intermediate** / Deep understanding of 02 Intermediate
2. **Implement tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i** / End-to-end implementation
3. **ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t** / Performance evaluation
4. **Tá»‘i Æ°u hÃ³a model** / Model optimization

## ğŸ“Š Dataset / Bá»™ Dá»¯ Liá»‡u

```python
# Sample dataset creation
import pandas as pd
import numpy as np

def create_sample_dataset():
    '''
    Create sample dataset for 02 Intermediate project
    '''
    np.random.seed(42)
    n_samples = 1000
    
    # Generate features
    X = np.random.randn(n_samples, 10)
    
    # Generate target (example for regression)
    y = np.dot(X, np.random.randn(10)) + np.random.randn(n_samples) * 0.1
    
    # Create DataFrame
    df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])
    df['target'] = y
    
    return df

# Usage
dataset = create_sample_dataset()
print(f"Dataset shape: {dataset.shape}")
```

## ğŸ› ï¸ Implementation Steps / CÃ¡c BÆ°á»›c Thá»±c Hiá»‡n

### Step 1: Data Preparation / BÆ°á»›c 1: Chuáº©n Bá»‹ Dá»¯ Liá»‡u
```python
def prepare_project_data(df):
    '''
    Prepare data for 02 Intermediate project
    '''
    # Handle missing values
    df = df.dropna()
    
    # Feature scaling
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    
    X = df.drop('target', axis=1)
    y = df['target']
    
    X_scaled = scaler.fit_transform(X)
    
    return X_scaled, y, scaler
```

### Step 2: Model Development / BÆ°á»›c 2: PhÃ¡t Triá»ƒn Model
```python
def develop_02_intermediate_model(X, y):
    '''
    Develop 02 Intermediate model for project
    '''
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_squared_error, r2_score
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Import and train model (example with Linear Regression)
    from sklearn.linear_model import LinearRegression
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Evaluate
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    print(f"Model Performance:")
    print(f"MSE: {mse:.4f}")
    print(f"RÂ²: {r2:.4f}")
    
    return model, y_pred
```

### Step 3: Model Optimization / BÆ°á»›c 3: Tá»‘i Æ¯u HÃ³a Model
```python
def optimize_02_intermediate_model(X, y):
    '''
    Optimize 02 Intermediate model using hyperparameter tuning
    '''
    from sklearn.model_selection import GridSearchCV
    from sklearn.linear_model import Ridge
    
    # Define parameter grid
    param_grid = {
        'alpha': [0.1, 1.0, 10.0, 100.0],
        'solver': ['auto', 'svd', 'cholesky']
    }
    
    # Grid search
    grid_search = GridSearchCV(
        Ridge(), param_grid, cv=5, scoring='neg_mean_squared_error'
    )
    grid_search.fit(X, y)
    
    print(f"Best parameters: {grid_search.best_params_}")
    print(f"Best score: {-grid_search.best_score_:.4f}")
    
    return grid_search.best_estimator_
```

## ğŸ“ˆ Evaluation / ÄÃ¡nh GiÃ¡

### Metrics / CÃ¡c Chá»‰ Sá»‘
- **MSE**: Mean Squared Error
- **RMSE**: Root Mean Squared Error  
- **MAE**: Mean Absolute Error
- **RÂ²**: Coefficient of Determination

### Visualization / Minh Há»a
```python
def visualize_project_results(y_true, y_pred):
    '''
    Visualize project results
    '''
    import matplotlib.pyplot as plt
    
    plt.figure(figsize=(12, 4))
    
    # Prediction vs Actual
    plt.subplot(1, 2, 1)
    plt.scatter(y_true, y_pred, alpha=0.5)
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')
    plt.xlabel('Actual Values')
    plt.ylabel('Predicted Values')
    plt.title('Prediction vs Actual')
    
    # Residuals
    plt.subplot(1, 2, 2)
    residuals = y_true - y_pred
    plt.scatter(y_pred, residuals, alpha=0.5)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title('Residual Plot')
    
    plt.tight_layout()
    plt.show()
```

## ğŸ“ Deliverables / Sáº£n Pháº©m

1. **Code hoÃ n chá»‰nh** / Complete code
2. **BÃ¡o cÃ¡o káº¿t quáº£** / Results report
3. **Presentation slides** / Slides thuyáº¿t trÃ¬nh
4. **Demo video** / Video demo

## ğŸ”— Related Links / LiÃªn Káº¿t LiÃªn Quan

- [Theory](./THEORY_02_intermediate.md)
- [Implementation](./IMPLEMENTATION_02_intermediate.md)
- [Code Examples](./CODE_EXAMPLES_02_intermediate.md)
- [Quiz](./QUIZ_02_intermediate.md)
