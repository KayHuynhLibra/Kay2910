#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 1 Implementation: T·∫°o n·ªôi dung c∆° b·∫£n cho t·∫•t c·∫£ th∆∞ m·ª•c con, s·ª≠a l·ªói n·ªôi suy chu·ªói v√† ƒë·ªïi t√™n file theo topic.
"""

import os
from pathlib import Path

def sanitize_topic(topic):
    return topic.lower().replace(' ', '_').replace('-', '_')

def create_theory_file(folder_path, topic):
    """T·∫°o file THEORY_<topic>.md cho th∆∞ m·ª•c con"""
    topic_safe = sanitize_topic(topic)
    content = f'''# üìö L√Ω Thuy·∫øt - {topic}

## üéØ T·ªïng Quan

{topic} l√† m·ªôt kh√°i ni·ªám quan tr·ªçng trong lƒ©nh v·ª±c AI/ML. B√†i vi·∫øt n√†y s·∫Ω cung c·∫•p c√°i nh√¨n t·ªïng quan v·ªÅ l√Ω thuy·∫øt ƒë·∫±ng sau {topic.lower()}.

## üìñ Kh√°i Ni·ªám C∆° B·∫£n

### ƒê·ªãnh Nghƒ©a
{topic} l√† m·ªôt ph∆∞∆°ng ph√°p/k·ªπ thu·∫≠t ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ...

### Nguy√™n L√Ω Ho·∫°t ƒê·ªông
- **Principle 1**: M√¥ t·∫£ nguy√™n l√Ω ƒë·∫ßu ti√™n
- **Principle 2**: M√¥ t·∫£ nguy√™n l√Ω th·ª© hai
- **Principle 3**: M√¥ t·∫£ nguy√™n l√Ω th·ª© ba

### ·ª®ng D·ª•ng Th·ª±c T·∫ø
- ·ª®ng d·ª•ng trong lƒ©nh v·ª±c 1
- ·ª®ng d·ª•ng trong lƒ©nh v·ª±c 2
- ·ª®ng d·ª•ng trong lƒ©nh v·ª±c 3

## üî¨ L√Ω Thuy·∫øt N√¢ng Cao

### Mathematical Foundation
C√°c c√¥ng th·ª©c to√°n h·ªçc c∆° b·∫£n:

    # Formula 1
    formula_1 = "y = f(x)"

    # Formula 2
    formula_2 = "loss = Œ£(prediction - actual)¬≤"

### Algorithmic Complexity
- **Time Complexity**: O(n)
- **Space Complexity**: O(1)
- **Optimization**: C√°c ph∆∞∆°ng ph√°p t·ªëi ∆∞u

### Advantages & Disadvantages
**∆Øu ƒëi·ªÉm:**
- ∆Øu ƒëi·ªÉm 1
- ∆Øu ƒëi·ªÉm 2
- ∆Øu ƒëi·ªÉm 3

**Nh∆∞·ª£c ƒëi·ªÉm:**
- Nh∆∞·ª£c ƒëi·ªÉm 1
- Nh∆∞·ª£c ƒëi·ªÉm 2
- Nh∆∞·ª£c ƒëi·ªÉm 3

## üìö T√†i Li·ªáu Tham Kh·∫£o

1. **Book 1**: Author - Title (Year)
2. **Paper 1**: Author - Title (Year)
3. **Research 1**: Author - Title (Year)
4. **Online Course**: Course Name - Platform
5. **Documentation**: Official Documentation

## üéØ K·∫øt Lu·∫≠n

{topic} l√† m·ªôt c√¥ng c·ª• m·∫°nh m·∫Ω trong AI/ML, cung c·∫•p n·ªÅn t·∫£ng cho nhi·ªÅu ·ª©ng d·ª•ng th·ª±c t·∫ø. Vi·ªác hi·ªÉu r√µ l√Ω thuy·∫øt ƒë·∫±ng sau s·∫Ω gi√∫p b·∫°n √°p d·ª•ng hi·ªáu qu·∫£ trong c√°c d·ª± √°n th·ª±c t·∫ø.

## üîó Li√™n K·∫øt Li√™n Quan

- [Implementation Guide](./IMPLEMENTATION_{topic_safe}.md)
- [Code Examples](./CODE_EXAMPLES_{topic_safe}.md)
- [Best Practices](./BEST_PRACTICES_{topic_safe}.md)
- [Complex Problems](./COMPLEX_PROBLEMS.md)
'''
    file_path = Path(folder_path) / f"THEORY_{topic_safe}.md"
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"‚úÖ Created: {file_path}")

def create_implementation_file(folder_path, topic):
    """T·∫°o file IMPLEMENTATION_<topic>.md cho th∆∞ m·ª•c con"""
    topic_safe = sanitize_topic(topic)
    content = f'''# üõ†Ô∏è Implementation Guide - {topic}

## üéØ T·ªïng Quan

H∆∞·ªõng d·∫´n chi ti·∫øt c√°ch implement {topic.lower()} t·ª´ c∆° b·∫£n ƒë·∫øn n√¢ng cao.

## üìã Prerequisites

### Ki·∫øn Th·ª©c C·∫ßn C√≥
- Python programming (intermediate level)
- Basic mathematics (linear algebra, calculus)
- Data structures and algorithms
- Basic understanding of machine learning concepts

### Tools & Libraries

    # Core libraries
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns

    # Machine Learning
    from sklearn import metrics, model_selection
    from sklearn.preprocessing import StandardScaler

    # Deep Learning (if applicable)
    import torch
    import tensorflow as tf

    # Visualization
    import plotly.express as px
    import plotly.graph_objects as go

## üöÄ Basic Implementation

### Step 1: Data Preparation

    # Load and prepare data
    def prepare_data(data_path):
        """
        Prepare data for {topic.lower()}
        Args:
            data_path: Path to data file
        Returns:
            X: Features
            y: Target variable
        """
        # Load data
        data = pd.read_csv(data_path)
        # Handle missing values
        data = data.dropna()
        # Separate features and target
        X = data.drop('target', axis=1)
        y = data['target']
        return X, y

### Step 2: Model Implementation

    # Basic implementation
    def basic_{topic_safe}(X, y):
        """
        Basic implementation of {topic.lower()}
        Args:
            X: Input features
            y: Target variable
        Returns:
            model: Trained model
        """
        # Implementation code here
        pass

### Step 3: Training and Evaluation

    # Train and evaluate model
    def train_and_evaluate(X, y):
        """
        Train and evaluate the model
        """
        # Split data
        X_train, X_test, y_train, y_test = model_selection.train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        # Train model
        model = basic_{topic_safe}(X_train, y_train)
        # Make predictions
        predictions = model.predict(X_test)
        # Evaluate
        accuracy = metrics.accuracy_score(y_test, predictions)
        return model, accuracy

## üîß Advanced Implementation

### Optimization Techniques
- **Hyperparameter Tuning**: Grid search, random search, Bayesian optimization
- **Feature Engineering**: Feature selection, feature creation, dimensionality reduction
- **Ensemble Methods**: Combining multiple models
- **Cross-Validation**: K-fold, stratified, time series split

### Error Handling

    import logging
    # Setup logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    def robust_implementation(X, y):
        """
        Robust implementation with error handling
        """
        try:
            # Implementation with error handling
            model = basic_{topic_safe}(X, y)
            logger.info("Model trained successfully")
            return model
        except Exception as e:
            logger.error(f"Error training model: {{e}}")
            raise

### Performance Optimization

    # Performance optimization
    def optimized_implementation(X, y):
        """
        Optimized implementation for better performance
        """
        # Use vectorized operations
        # Minimize memory usage
        # Optimize for speed
        pass

## üìä Evaluation

### Metrics
- **Accuracy**: Overall correctness
- **Precision**: True positives / (True positives + False positives)
- **Recall**: True positives / (True positives + False negatives)
- **F1-Score**: Harmonic mean of precision and recall
- **AUC-ROC**: Area under the ROC curve

### Visualization

    def plot_results(y_true, y_pred):
        """
        Plot evaluation results
        """
        # Confusion matrix
        cm = metrics.confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
        plt.title('Confusion Matrix')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.show()
        # ROC curve
        fpr, tpr, _ = metrics.roc_curve(y_true, y_pred)
        auc = metrics.auc(fpr, tpr)
        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {{auc:.2f}})')
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curve')
        plt.legend()
        plt.show()

## üéØ Best Practices

1. **Data Quality**: Always check data quality before implementation
2. **Feature Engineering**: Invest time in feature engineering
3. **Cross-Validation**: Use cross-validation to avoid overfitting
4. **Hyperparameter Tuning**: Tune hyperparameters systematically
5. **Documentation**: Document your implementation thoroughly

## üö® Common Mistakes

1. **Data Leakage**: Using test data during training
2. **Overfitting**: Model performs well on training but poorly on test
3. **Underfitting**: Model is too simple for the data
4. **Ignoring Data Distribution**: Not checking data distribution
5. **Not Scaling Features**: Using unscaled features when needed

## üìö References

1. **Official Documentation**: Link to official docs
2. **Research Papers**: Relevant research papers
3. **Online Courses**: Recommended courses
4. **Books**: Recommended books
5. **Tutorials**: Online tutorials

## üîó Li√™n K·∫øt Li√™n Quan

- [Theory](./THEORY_{topic_safe}.md)
- [Code Examples](./CODE_EXAMPLES_{topic_safe}.md)
- [Best Practices](./BEST_PRACTICES_{topic_safe}.md)
- [Complex Problems](./COMPLEX_PROBLEMS.md)
'''
    file_path = Path(folder_path) / f"IMPLEMENTATION_{topic_safe}.md"
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"‚úÖ Created: {file_path}")

def create_code_examples_file(folder_path, topic):
    """T·∫°o file CODE_EXAMPLES_<topic>.md cho th∆∞ m·ª•c con"""
    topic_safe = sanitize_topic(topic)
    content = f'''# üíª Code Examples - {topic}

## üéØ T·ªïng Quan

C√°c v√≠ d·ª• code th·ª±c t·∫ø cho {topic.lower()}.

## üìö Basic Examples

### Example 1: Simple Implementation

    import numpy as np
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score

    def simple_{topic_safe}(X, y):
        """
        Simple implementation of {topic.lower()}
        Parameters:
        X: Input features (numpy array or pandas DataFrame)
        y: Target variable (numpy array or pandas Series)
        Returns:
        model: Trained model
        """
        # Implementation here
        pass

    # Usage example
    if __name__ == "__main__":
        # Load sample data
        from sklearn.datasets import make_classification
        X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        # Train model
        model = simple_{topic_safe}(X_train, y_train)
        # Make predictions
        predictions = model.predict(X_test)
        # Evaluate
        accuracy = accuracy_score(y_test, predictions)
        print(f"Accuracy: {{accuracy:.4f}}")

## üîß Advanced Examples

### Example 2: Custom Implementation

    class Custom{topic.title().replace(' ', '').replace('-', '')}:
        """
        Custom implementation of {topic.lower()}
        """
        def __init__(self, learning_rate=0.01, max_iterations=1000):
            self.learning_rate = learning_rate
            self.max_iterations = max_iterations
            self.weights = None
            self.bias = None
            self.history = []
        def fit(self, X, y):
            n_samples, n_features = X.shape
            self.weights = np.zeros(n_features)
            self.bias = 0
            for iteration in range(self.max_iterations):
                predictions = self.predict(X)
                dw = (1/n_samples) * np.dot(X.T, (predictions - y))
                db = np.mean(predictions - y)
                self.weights -= self.learning_rate * dw
                self.bias -= self.learning_rate * db
                loss = np.mean((predictions - y) ** 2)
                self.history.append(loss)
                if len(self.history) > 10 and abs(self.history[-1] - self.history[-10]) < 1e-6:
                    break
        def predict(self, X):
            return np.dot(X, self.weights) + self.bias
        def plot_training_history(self):
            import matplotlib.pyplot as plt
            plt.figure(figsize=(10, 6))
            plt.plot(self.history)
            plt.title('Training History')
            plt.xlabel('Iteration')
            plt.ylabel('Loss')
            plt.grid(True)
            plt.show()

## üìö References

1. **Official Documentation**: Link to official docs
2. **GitHub Examples**: Link to GitHub examples
3. **Online Tutorials**: Link to tutorials
4. **Research Papers**: Link to relevant papers
5. **Books**: Link to recommended books

## üîó Li√™n K·∫øt Li√™n Quan

- [Theory](./THEORY_{topic_safe}.md)
- [Implementation](./IMPLEMENTATION_{topic_safe}.md)
- [Best Practices](./BEST_PRACTICES_{topic_safe}.md)
- [Complex Problems](./COMPLEX_PROBLEMS.md)
'''
    file_path = Path(folder_path) / f"CODE_EXAMPLES_{topic_safe}.md"
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"‚úÖ Created: {file_path}")

def create_best_practices_file(folder_path, topic):
    """T·∫°o file BEST_PRACTICES_<topic>.md cho th∆∞ m·ª•c con"""
    topic_safe = sanitize_topic(topic)
    content = f'''# ‚≠ê Best Practices - {topic}

## üéØ T·ªïng Quan

C√°c best practices khi l√†m vi·ªác v·ªõi {topic.lower()}.

- **Always validate data**
- **Use version control**
- **Document code and experiments**
- **Monitor model performance**
- **Follow security best practices**

## üîó Li√™n K·∫øt Li√™n Quan

- [Theory](./THEORY_{topic_safe}.md)
- [Implementation](./IMPLEMENTATION_{topic_safe}.md)
- [Code Examples](./CODE_EXAMPLES_{topic_safe}.md)
- [Complex Problems](./COMPLEX_PROBLEMS.md)
'''
    file_path = Path(folder_path) / f"BEST_PRACTICES_{topic_safe}.md"
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"‚úÖ Created: {file_path}")

def create_requirements_file(folder_path, topic):
    topic_safe = sanitize_topic(topic)
    content = '''# Core Libraries
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.4.0
seaborn>=0.11.0

# Machine Learning
scikit-learn>=1.0.0
xgboost>=1.5.0
lightgbm>=3.3.0

# Deep Learning (if needed)
tensorflow>=2.8.0
torch>=1.10.0
transformers>=4.20.0

# Data Processing
nltk>=3.7
opencv-python>=4.5.0
pillow>=8.3.0

# Visualization
plotly>=5.0.0
bokeh>=2.4.0

# Utilities
jupyter>=1.0.0
ipykernel>=6.0.0
'''
    file_path = Path(folder_path) / f"requirements_{topic_safe}.txt"
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"‚úÖ Created: {file_path}")

def main():
    print("üöÄ Phase 1: B·∫Øt ƒë·∫ßu t·∫°o n·ªôi dung c∆° b·∫£n cho t·∫•t c·∫£ th∆∞ m·ª•c con...")
    subdirs = []
    for root, dirs, files in os.walk('.'):
        if root == '.' or any(part.startswith('.') for part in Path(root).parts):
            continue
        subdirs.append((root, Path(root).name.replace('_', ' ').title()))
    created_count = 0
    for folder_path, topic in subdirs:
        try:
            existing_files = set()
            if Path(folder_path).exists():
                for file in Path(folder_path).glob("*.*"):
                    existing_files.add(file.name)
            topic_safe = sanitize_topic(topic)
            if f"THEORY_{topic_safe}.md" not in existing_files:
                create_theory_file(folder_path, topic)
            if f"IMPLEMENTATION_{topic_safe}.md" not in existing_files:
                create_implementation_file(folder_path, topic)
            if f"CODE_EXAMPLES_{topic_safe}.md" not in existing_files:
                create_code_examples_file(folder_path, topic)
            if f"BEST_PRACTICES_{topic_safe}.md" not in existing_files:
                create_best_practices_file(folder_path, topic)
            if f"requirements_{topic_safe}.txt" not in existing_files:
                create_requirements_file(folder_path, topic)
            created_count += 1
            print(f"‚úÖ Enhanced: {folder_path}")
        except Exception as e:
            print(f"‚ùå Error creating content for {folder_path}: {e}")
    print(f"\nüéâ Phase 1 Ho√†n th√†nh! ƒê√£ t·∫°o n·ªôi dung c∆° b·∫£n cho {created_count} th∆∞ m·ª•c con")
    print("üìù M·ªói th∆∞ m·ª•c con gi·ªù c√≥:")
    print("   - THEORY_<topic>.md: L√Ω thuy·∫øt chi ti·∫øt")
    print("   - IMPLEMENTATION_<topic>.md: H∆∞·ªõng d·∫´n implement")
    print("   - CODE_EXAMPLES_<topic>.md: V√≠ d·ª• code")
    print("   - BEST_PRACTICES_<topic>.md: Best practices")
    print("   - requirements_<topic>.txt: Dependencies")
    print("   - COMPLEX_PROBLEMS.md: 5 b√†i to√°n ph·ª©c t·∫°p (ƒë√£ c√≥)")

if __name__ == "__main__":
    main() 